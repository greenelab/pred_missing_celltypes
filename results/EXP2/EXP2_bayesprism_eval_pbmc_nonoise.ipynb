{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c377a42a",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [5]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92797e",
   "metadata": {
    "papermill": {
     "duration": 0.063691,
     "end_time": "2023-11-08T17:03:59.832591",
     "exception": false,
     "start_time": "2023-11-08T17:03:59.768900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**EXP2 Predicitng Missing Cell-Types from Bulks using BayesPrism Residual**\n",
    "\n",
    "*This file includes EXP2 results (details outlined in link below).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63bafa4",
   "metadata": {
    "papermill": {
     "duration": 0.059593,
     "end_time": "2023-11-08T17:03:59.951373",
     "exception": false,
     "start_time": "2023-11-08T17:03:59.891780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experimental Details: https://docs.google.com/spreadsheets/d/1fMV_URm95iPh-6rew-Be27I1-i8PNgGNWi2D_UO2V9w/edit#gid=0\n",
    "\n",
    "Summary: Analyzing results form BayesPrism deconvolution done in EXP2_bayesprism_pbmc.R.\n",
    "\n",
    "*This file is intended to be run through Papermill in EXP2.py. See EXP2.py for details*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e77504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T17:04:00.078798Z",
     "iopub.status.busy": "2023-11-08T17:04:00.078289Z",
     "iopub.status.idle": "2023-11-08T17:04:06.300792Z",
     "shell.execute_reply": "2023-11-08T17:04:06.301038Z"
    },
    "papermill": {
     "duration": 6.290539,
     "end_time": "2023-11-08T17:04:06.301243",
     "exception": false,
     "start_time": "2023-11-08T17:04:00.010704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the dependencies\n",
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "sys.path.insert(1, '../')\n",
    "sys.path.insert(1, '../../../../../')\n",
    "\n",
    "from functions import sn_sc_preprocess\n",
    "from functions import validation_processing as vp\n",
    "from importlib import reload\n",
    "reload(sn_sc_preprocess)\n",
    "reload(vp)\n",
    "# general imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from numpy import array\n",
    "from numpy import diag\n",
    "from numpy import dot\n",
    "from numpy import zeros\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import AnnData as ad\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import scipy as sp\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import scipy as sp\n",
    "from scipy.optimize import nnls\n",
    "from scipy.stats import ttest_ind\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import seaborn as sns\n",
    "from openTSNE import TSNE\n",
    "from openTSNE import TSNEEmbedding\n",
    "from openTSNE import affinity\n",
    "from openTSNE import initialization\n",
    "#sklearns\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# programming stuff\n",
    "import time\n",
    "import os, sys\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6f68a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T17:04:06.424799Z",
     "iopub.status.busy": "2023-11-08T17:04:06.424239Z",
     "iopub.status.idle": "2023-11-08T17:04:06.425542Z",
     "shell.execute_reply": "2023-11-08T17:04:06.425908Z"
    },
    "papermill": {
     "duration": 0.064656,
     "end_time": "2023-11-08T17:04:06.426027",
     "exception": false,
     "start_time": "2023-11-08T17:04:06.361371",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### set the study ###\n",
    "#####################\n",
    "#these parameters are set in papermill \n",
    "res_name = \"MCT_pbmc_EXP2\"\n",
    "pseudos_name = \"MCT_pbmc_EXP2\"\n",
    "path = \"/../data/\"\n",
    "aug_data_path = \"/../data/EXP2/BayesPrism/\"\n",
    "data_path = \"/../data/EXP1/\"\n",
    "bp_path = \"/../data/EXP2/BP_results/\"\n",
    "prop_type =\"random\"\n",
    "noise_type = \"nonoise\"\n",
    "num_missing_cells = [0,1,2,3,4]\n",
    "nmf_cut = \"minimum_value\"\n",
    "num_samples = 10000\n",
    "random_seed = 88\n",
    "prop_type =\"random\"\n",
    "noise_type = \"nonoise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db11afb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T17:04:06.548507Z",
     "iopub.status.busy": "2023-11-08T17:04:06.547983Z",
     "iopub.status.idle": "2023-11-08T17:04:06.549452Z",
     "shell.execute_reply": "2023-11-08T17:04:06.549703Z"
    },
    "papermill": {
     "duration": 0.064735,
     "end_time": "2023-11-08T17:04:06.549831",
     "exception": false,
     "start_time": "2023-11-08T17:04:06.485096",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "res_name = \"MCT_pbmc_EXP2\"\n",
    "pseudos_name = \"MCT_pbmc_EXP1\"\n",
    "path = \"/data/\"\n",
    "aug_data_path = \"/data/EXP2/\"\n",
    "data_path = \"/data/EXP1/\"\n",
    "bp_path = \"/data/EXP2/BP_results/\"\n",
    "noise_type = \"nonoise\"\n",
    "random_seed = 88\n",
    "num_missing_cells = [0, 1, 2, 3, 4]\n",
    "num_samples = 10000\n",
    "nmf_cut = \"minimum_value\"\n",
    "kernel_name = \"env_ml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d180b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T17:04:06.672344Z",
     "iopub.status.busy": "2023-11-08T17:04:06.671820Z",
     "iopub.status.idle": "2023-11-08T17:04:06.673393Z",
     "shell.execute_reply": "2023-11-08T17:04:06.673664Z"
    },
    "papermill": {
     "duration": 0.06474,
     "end_time": "2023-11-08T17:04:06.673782",
     "exception": false,
     "start_time": "2023-11-08T17:04:06.609042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual_path = os.getcwd()\n",
    "path = f\"{actual_path}{path}\"\n",
    "aug_data_path = f\"{actual_path}{aug_data_path}\"\n",
    "data_path = f\"{actual_path}{data_path}\"\n",
    "bp_path = f\"{actual_path}{bp_path}\"\n",
    "\n",
    "bulk_type = f\"{prop_type}prop_{noise_type}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c9c72",
   "metadata": {
    "papermill": {
     "duration": 0.059217,
     "end_time": "2023-11-08T17:04:06.792468",
     "exception": false,
     "start_time": "2023-11-08T17:04:06.733251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Opening mixture file of pseudobulks and anndata for reference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dcc18f",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d233e13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T17:04:06.916183Z",
     "iopub.status.busy": "2023-11-08T17:04:06.915775Z",
     "iopub.status.idle": "2023-11-08T17:04:07.292126Z",
     "shell.execute_reply": "2023-11-08T17:04:07.291710Z"
    },
    "papermill": {
     "duration": 0.440792,
     "end_time": "2023-11-08T17:04:07.292344",
     "exception": true,
     "start_time": "2023-11-08T17:04:06.851552",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ivicha/Documents/Project_missingcelltype/pred_missing_celltypes/data/EXP2/MCT_pbmc_EXP2_randomprop_nonoise_mixture.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d3/x10lxf7x1n37__s3n36qxmlw0000gp/T/ipykernel_3919/2190783296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpseudo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpseudo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Open the CSV file of mixture used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpseudo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpseudo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#extracting gene_ids and setting as columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpseudo_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'gene_ids'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/env_ml/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ivicha/Documents/Project_missingcelltype/pred_missing_celltypes/data/EXP2/MCT_pbmc_EXP2_randomprop_nonoise_mixture.csv'"
     ]
    }
   ],
   "source": [
    "pseudo_path = os.path.join(aug_data_path, f\"{res_name}_{bulk_type}_mixture.csv\")\n",
    "pseudo_path = Path(pseudo_path)\n",
    "# Open the CSV file of mixture used\n",
    "pseudo_df = pd.read_csv(pseudo_path, sep=\",\")\n",
    "#extracting gene_ids and setting as columns\n",
    "pseudo_df.rename(columns = {'Unnamed: 0':'gene_ids'}, inplace = True)\n",
    "gene_ids = pseudo_df[\"gene_ids\"]\n",
    "pseudo_df = pseudo_df.T\n",
    "pseudo_df.columns = gene_ids\n",
    "pseudo_df = pseudo_df.drop(labels = \"gene_ids\")\n",
    "pseudo_df_copy = pseudo_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6a0c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#and importing anndata object\n",
    "adata_path = os.path.join(data_path, f\"{pseudos_name}_adata_notlog.h5ad\")\n",
    "adata_path = Path(adata_path)\n",
    "sn_adata = sc.read_h5ad(adata_path)\n",
    "sn_adata_copy = sn_adata.copy()\n",
    "sn_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c571ca",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Counter(sn_adata.obs[\"cell_types\"]))\n",
    "# define the number of cells and the list of missing cell counts\n",
    "num_cells = len(sn_adata.obs.cell_types.unique())\n",
    "cell_order = sn_adata.obs.cell_types.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59682f8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making cell type reference without scaling\n",
    "cell_types = sn_adata.obs[\"cell_types\"].unique()\n",
    "gene_ids = sn_adata.var[\"gene_ids\"]\n",
    "ref_raw = pd.DataFrame(index = gene_ids, columns = cell_types)\n",
    "for cell_type in cell_types:\n",
    "    cell_df = sn_adata[sn_adata.obs[\"cell_types\"].isin([cell_type])]\n",
    "    cell_sample = sk.utils.resample(cell_df, n_samples = num_samples, replace=True)\n",
    "    x = cell_sample.X.sum(axis=0)\n",
    "    sum_over_genes = pd.DataFrame(x).T\n",
    "    #and save to df dict\n",
    "    ref_raw[cell_type] = sum_over_genes.values\n",
    "ref_raw.index = gene_ids.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724333e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clippign before scaling to 95th pecentile\n",
    "ref_raw_val = ref_raw.values\n",
    "clip_upper = np.quantile(ref_raw_val, 0.95)\n",
    "ref_raw_val = np.clip(ref_raw_val, 0, clip_upper)\n",
    "#and scaling to be between values 0 and 1 to use for NNLS\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ref_raw_val)\n",
    "ref_df = scaler.transform(ref_raw_val)\n",
    "ref_df = pd.DataFrame(ref_df, index = gene_ids, columns = cell_types)\n",
    "ref_raw = pd.DataFrame(ref_raw_val, index = gene_ids, columns = cell_types)\n",
    "ref_df.index = gene_ids.index\n",
    "ref_df_copy = ref_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d9424",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Reading In and QCing the BayesPrism Results:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7786fe9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "BayesPrism Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379d341",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import all BayesPrism results (through using InstaPrism) and real proportions\n",
    "bp_prop = dict()\n",
    "real_prop_reb = dict()\n",
    "real_prop = dict()\n",
    "ref_bp = dict()\n",
    "gene_ids = dict()\n",
    "for num in num_missing_cells:\n",
    "    bp_results_path = os.path.join(bp_path, f\"{res_name}_{num}missing_{bulk_type}_InstaPrism_results.csv\")\n",
    "    bp_results_path = Path(bp_results_path)\n",
    "    # Open the CSV file in read mode\n",
    "    bp_prop[num] = pd.read_csv(bp_results_path, sep=\"\\t\")\n",
    "    bp_prop[num] = bp_prop[num].T\n",
    "\n",
    "    #real proportions\n",
    "    realprop_results_path = os.path.join(aug_data_path, f\"{res_name}_{num}missing_{bulk_type}_prop.csv\")\n",
    "    realprop_results_path = Path(realprop_results_path)\n",
    "    # Open the CSV file in read mode\n",
    "    real_prop[num] = pd.read_csv(realprop_results_path, sep=\",\")\n",
    "\n",
    "    #real rebalanced proportions\n",
    "    realrebprop_results_path = os.path.join(aug_data_path, f\"{res_name}_{num}missing_{bulk_type}_prop.csv\")\n",
    "    realrebprop_results_path = Path(realrebprop_results_path)\n",
    "    # Open the CSV file in read mode\n",
    "    real_prop_reb[num] = pd.read_csv(realrebprop_results_path, sep=\",\")\n",
    "\n",
    "    #and the reference used in BP\n",
    "    ref_results_path = os.path.join(bp_path, f\"{res_name}_{num}missing_{bulk_type}_InstaPrism_usedref.csv\")\n",
    "    ref_results_path = Path(ref_results_path)\n",
    "    # Open the CSV file in read mode\n",
    "    ref_bp[num] = pd.read_csv(ref_results_path, sep=\"\\t\")\n",
    "    #gene ids used for each\n",
    "    gene_ids[num] = ref_bp[num].index\n",
    "    #match columns and index\n",
    "    bp_prop[num].columns =  real_prop[num].columns\n",
    "    bp_prop[num].index =  real_prop[num].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822399c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_prop = real_prop_reb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c528b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "QC imported files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7fadc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bp_prop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff330988",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_prop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec1039",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_prop_reb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae68c1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_bp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a5777",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The BayesPrism reference should sum to 1 for each cell type expression\n",
    "ref_bp[0].sum(axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d57c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudo_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6116d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e587210",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cutting to genes used in each one\n",
    "pseudo_df = dict()\n",
    "sn_adata = dict()\n",
    "ref_df = dict()\n",
    "for num in num_missing_cells:\n",
    "    pseudo_df[num] = pseudo_df_copy[gene_ids[num]]\n",
    "    sn_adata[num] = sn_adata_copy[:, gene_ids[num]]\n",
    "    ref_df[num] = ref_df_copy.loc[gene_ids[num], :]\n",
    "    #and matching columns of present cells\n",
    "    ref_df[num] = ref_df[num].filter(ref_bp[num].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60540f68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Visualize BayesPrism proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27c1ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Evaluation performance with no cell types missing, expect to be very close to 1.\n",
    "num = 0 \n",
    "for col_cell in real_prop[num].columns:\n",
    "    x = real_prop[num][col_cell].values.astype(float)\n",
    "    y = bp_prop[num][col_cell].values.astype(float)\n",
    "    correlation_coefficient = np.corrcoef(x, y)[0,1]\n",
    "    plt.scatter(x, y, label= f\"{col_cell}\")\n",
    "    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = \"red\")\n",
    "    r, p = stats.pearsonr(x, y)\n",
    "    plt.annotate('r = {:.2f}'.format(r), xy=(0.7, 0.9), xycoords='axes fraction')\n",
    "    plt.xlabel('Real Proportions')\n",
    "    plt.ylabel('Estimated Proportions (without missing cell)')\n",
    "    plt.title(f'Correlation of Real and BayesPrism Pred Props, {num} Cell Missing')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d2afa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Comparnig performance for all cell types with num_cells_missing.\n",
    "# define colormap for coloring cell types\n",
    "cmap = get_cmap('tab20') \n",
    "for num in num_missing_cells:\n",
    "    real_proportions = real_prop_reb[num].values.astype(float) #real proportions of present cells\n",
    "    estimated_proportions = bp_prop[num].values.astype(float) #estimated proportions of present cells.\n",
    "    cell_types = real_prop_reb[num].columns.tolist() \n",
    "    # Print the shapes of the matrices\n",
    "    print(\"Real Proportions shape:\", real_proportions.shape)\n",
    "    print(\"Estimated Proportions shape:\", estimated_proportions.shape)\n",
    "    correlation_coefficient = np.corrcoef(real_proportions, estimated_proportions)[0, 1]\n",
    "    #scatter plot with colored points for each cell type\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, cell_type in enumerate(cell_types):\n",
    "        x = real_proportions[:, i]\n",
    "        y = estimated_proportions[:, i]\n",
    "        color = cmap(i)  #unique color for each cell type\n",
    "        ax.scatter(x, y, label=cell_type, color=color)\n",
    "    #fit a regression line\n",
    "    m, b = np.polyfit(real_proportions.flatten(), estimated_proportions.flatten(), 1)\n",
    "    plt.plot(real_proportions.flatten(), m * real_proportions.flatten() + b, color=\"red\")\n",
    "    r, p = stats.pearsonr(real_proportions.flatten(), estimated_proportions.flatten())\n",
    "    plt.annotate(f'r = {r:.2f}', xy=(0.7, 0.9), xycoords='axes fraction')\n",
    "    plt.xlabel('Real Proportions')\n",
    "    plt.ylabel('Estimated Proportions (without missing cell)')\n",
    "    plt.title(f'Correlation of Real and NNLS Pred Props, {num} Cell Missing')\n",
    "    plt.legend(loc='best')  #show the cell type labels in the legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd16928",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Compare References:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d33190",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the difference between calculated and real proportions.\n",
    "custom_res_tot = dict()\n",
    "for num in num_missing_cells:\n",
    "    custom_res_tot[num] = real_prop[num].values - bp_prop[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710c62d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Distribution of residuals as the difference between calculated and real proportions.\n",
    "#the difference between calculated and real proportions.\n",
    "custom_res_tot = dict()\n",
    "for num in num_missing_cells:\n",
    "    custom_res_tot[num] = real_prop[num].values - bp_prop[num]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# List to store all the residual values\n",
    "residual_values = []\n",
    "\n",
    "# Iterate over the dataframes and extract the residual values\n",
    "for num_cells in num_missing_cells:\n",
    "    df = custom_res_tot[num_cells]\n",
    "    residuals = df.values.flatten()  # Flatten the dataframe to a 1D array\n",
    "    residual_values.append(residuals)\n",
    "\n",
    "# Plot the box and whisker plot for all the residuals\n",
    "ax.boxplot(residual_values, labels=num_missing_cells)\n",
    "ax.set_title(\"Residuals for Different No. Missing Cell Types: Random Proportions\")\n",
    "ax.set_xlabel(\"Number of Missing Cell Types\")\n",
    "ax.set_ylabel(\"Residuals (real - pred proportions)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1422f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Extracting Missing Cell Information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab191b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cells_to_miss = dict()\n",
    "missing_cell_tot  = dict()\n",
    "for num in num_missing_cells:\n",
    "    #cells that are missing\n",
    "    cells_to_miss[num] = np.setdiff1d(ref_df[0].columns, ref_bp[num].columns)\n",
    "    #extracting real proportions from missing cells\n",
    "    missing_cell_tot[num] = real_prop[0][cells_to_miss[num]]\n",
    "    print(f\"{num} missing: {missing_cell_tot[num].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f85ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the corresponding missing_cell_proportions\n",
    "missing_cell_prop = dict()\n",
    "missing_cell_prop[0] = []\n",
    "for num in num_missing_cells[1:]:\n",
    "    missing_cell_prop[num] = real_prop[0][missing_cell_tot[num].columns]  \n",
    "    print(f\"{num} missing: prop is {missing_cell_prop[num].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e500a56",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Calculate Residuals:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a72968",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1. Residual uses:\n",
    "\n",
    "pseudobulks - recreated_mat_all (reference used normalized (ref_bp) * calculated proportions (calc_prop_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd384a0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bp_prop[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8622ba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Residual: pseudobulks as used, minus reference of BP * calculated proportions\n",
    "residuals = dict()\n",
    "for num in num_missing_cells:\n",
    "    #cutting pseudobulk to match reference genes\n",
    "    pseudo_df_ = pseudo_df[num][ref_bp[num].index]\n",
    "    res = pseudo_df_.values - (bp_prop[num] @ ref_bp[num].T)\n",
    "    residuals[num] = pd.DataFrame(res, columns = gene_ids[num])\n",
    "residuals[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd401a9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_bp_scaled = dict()\n",
    "pseudo_scaled = dict()\n",
    "for num in num_missing_cells:\n",
    "    #clippign before scaling to 95th pecentile\n",
    "    ref_raw_val = ref_bp[num].values ##reference of bayes prism\n",
    "    clip_upper = np.quantile(ref_raw_val, 0.90)\n",
    "    ref_raw_val = np.clip(ref_raw_val, 0, clip_upper)\n",
    "    #and scaling to be between values 0 and 1 \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(ref_raw_val)\n",
    "    ref_scale = scaler.transform(ref_raw_val)\n",
    "    ref_bp_scaled[num] = pd.DataFrame(ref_scale, index = gene_ids[num], columns = real_prop[num].columns)\n",
    "\n",
    "    #clippign before scaling to 95th pecentile\n",
    "    pseudo_raw_val = pseudo_df[num][ref_bp[num].index].values ##pseudobulks\n",
    "    clip_upper = np.quantile(pseudo_raw_val, 0.90)\n",
    "    pseudo_raw_val = np.clip(pseudo_raw_val, 0, clip_upper)\n",
    "    #and scaling to be between values 0 and 1 \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(pseudo_raw_val)\n",
    "    pseudo_scale = scaler.transform(pseudo_raw_val)\n",
    "    pseudo_scaled[num] = pd.DataFrame(pseudo_scale, columns = gene_ids[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37ff92",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(ref_bp[1].max().max())\n",
    "print(ref_bp_scaled[1].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91dedb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pseudo_df[1].max().max())\n",
    "print(pseudo_scaled[1].max().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870df55",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Residual with the scaled pseudobulk and scaled bayes prism reference\n",
    "residuals_scaled = dict()\n",
    "for num in num_missing_cells:\n",
    "    res = (pseudo_scaled[num].values)  - (bp_prop[num] @ ref_bp_scaled[num].T)\n",
    "    residuals_scaled[num] = pd.DataFrame(res, columns = gene_ids[num])\n",
    "residuals_scaled[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e256826",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708aea2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distribution of residuals\n",
    "for num in num_missing_cells:\n",
    "    data = residuals[num].values\n",
    "    plt.figure(figsize=(4, 2)) \n",
    "    plt.hist(data.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(f'Residual Data Distribution: {num} cells missing')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25326ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distribution of residuals\n",
    "for num in num_missing_cells:\n",
    "    data = residuals_scaled[num].values\n",
    "    plt.figure(figsize=(4, 2)) \n",
    "    plt.hist(data.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(f'Residual Data Distribution: {num} cells missing')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d5a6e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Shifting distributions according to above plots, and calculating NMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f368c71",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shifting distribution of residuals to do NMF\n",
    "residuals_shift = residuals\n",
    "for num in num_missing_cells:\n",
    "    if nmf_cut == \"minimum_value\":\n",
    "        #calculate value to shift distributions minimally:\n",
    "        min_val = abs(np.min(np.min(residuals[num])))\n",
    "        print(min_val)\n",
    "        residuals_shift[num] = residuals[num] + min_val\n",
    "    elif nmf_cut == \"at_0\":\n",
    "        #cutting distribution at 0\n",
    "        residuals_shift[num][residuals_shift[num].values <= 0] = 0\n",
    "    data = residuals_shift[num].values\n",
    "    plt.figure(figsize=(4, 2)) \n",
    "    plt.hist(data.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(f'Residual Data Distribution: {num} cells missing')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94acc228",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#nmf on residual 1\n",
    "res_nmf = dict()\n",
    "for num in num_missing_cells:\n",
    "    num_nmf = num +1\n",
    "    nmf = NMF(n_components = num_nmf)\n",
    "    res_nmf_df = nmf.fit_transform(residuals_shift[num])\n",
    "    res_nmf_df = pd.DataFrame(res_nmf_df)\n",
    "    res_nmf[num] = res_nmf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc2933",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shift_scaleding distribution of residuals to do NMF\n",
    "residuals_shift_scaled = residuals_scaled\n",
    "for num in num_missing_cells:\n",
    "    if nmf_cut == \"minimum_value\":\n",
    "        #calculate value to shift_scaled distributions minimally:\n",
    "        min_val = abs(np.min(np.min(residuals_scaled[num])))\n",
    "        print(min_val)\n",
    "        residuals_shift_scaled[num] = residuals_scaled[num] + min_val\n",
    "    elif nmf_cut == \"at_0\":\n",
    "        #cutting distribution at 0\n",
    "        residuals_shift_scaled[num][residuals_shift_scaled[num].values <= 0] = 0\n",
    "    data = residuals_shift_scaled[num].values\n",
    "    plt.figure(figsize=(4, 2)) \n",
    "    plt.hist(data.flatten(), bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(f'Residual Data Distribution: {num} cells missing')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f0653",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#nmf on residual 1\n",
    "res_nmf_scaled = dict()\n",
    "for num in num_missing_cells:\n",
    "    num_nmf = num +1\n",
    "    nmf = NMF(n_components = num_nmf)\n",
    "    res_nmf_df = nmf.fit_transform(residuals_shift_scaled[num])\n",
    "    res_nmf_df = pd.DataFrame(res_nmf_df)\n",
    "    res_nmf_scaled[num] = res_nmf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec815a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a00424",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NMF Residual(by sample) compared to each missing celltype proportion\n",
    "#nmf on residual 1\n",
    "res_nmf = dict()\n",
    "for num in num_missing_cells:\n",
    "    num_nmf = num +1\n",
    "    nmf = NMF(n_components = num_nmf, max_iter=10000, init='nndsvd')\n",
    "    res_nmf_df = nmf.fit_transform(residuals_shift[num])\n",
    "    res_nmf_df = pd.DataFrame(res_nmf_df)\n",
    "    res_nmf[num] = res_nmf_df\n",
    "vp.factors_vs_proportions_rmse(res_nmf, missing_cell_prop, num_missing_cells, method = \"NMF\")\n",
    "#It is expected that only one column (factor) for each cell type (row) will be postivelly correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013d1ea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Residual_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a88ad2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NMF Residual(by sample) compared to each missing celltype proportion\n",
    "#nmf on residual 1\n",
    "res_nmf = dict()\n",
    "for num in num_missing_cells:\n",
    "    num_nmf = num + 1\n",
    "    nmf = NMF(n_components = num_nmf, max_iter = 10000, init='nndsvd')\n",
    "    res_nmf_df = nmf.fit_transform(residuals_shift_scaled[num])\n",
    "    res_nmf_df = pd.DataFrame(res_nmf_df)\n",
    "    res_nmf[num] = res_nmf_df\n",
    "vp.factors_vs_proportions_rmse(res_nmf, missing_cell_prop, num_missing_cells, method = \"NMF\")\n",
    "#It is expected that only one column (factor) for each cell type (row) will be postivelly correlated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env_ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.13861,
   "end_time": "2023-11-08T17:04:10.737734",
   "environment_variables": {},
   "exception": true,
   "input_path": "/Users/ivicha/Documents/Project_missingcelltype/pred_missing_celltypes/evaluation_experiments/EXP2_bayesprism_eval.ipynb",
   "output_path": "/Users/ivicha/Documents/Project_missingcelltype/pred_missing_celltypes/results/EXP2/EXP2_bayesprism_eval_pbmc_nonoise.ipynb",
   "parameters": {
    "aug_data_path": "/data/EXP2/",
    "bp_path": "/data/EXP2/BP_results/",
    "data_path": "/data/EXP1/",
    "kernel_name": "env_ml",
    "nmf_cut": "minimum_value",
    "noise_type": "nonoise",
    "num_missing_cells": [
     0,
     1,
     2,
     3,
     4
    ],
    "num_samples": 10000,
    "path": "/data/",
    "pseudos_name": "MCT_pbmc_EXP1",
    "random_seed": 88,
    "res_name": "MCT_pbmc_EXP2"
   },
   "start_time": "2023-11-08T17:03:58.599124",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c6e89b18067338bc7c1d6e0e5cf4a8a20dc26479be80b2cb656a6cd73a6c53b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}